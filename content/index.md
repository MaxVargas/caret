---
title: Welcome to Max^s spot on the internet!
---

Feel free to click around --- my website presence is still under construction but Quartz seems like a cool way to handle things.

A bit about me and this my plan for this place: I got a PhD in 2023 and decided to leave academics. I studied math and wanted to get more experience with software and computation. I also wanted more free time to invest in exploring and learning about whatever I want! As such, this site might end up becoming a log of whatever has been occupying my time recently. I'll add things to this site as they come along (and as I choose to add them) and try to keep this semi-regularly updated. No plans are super set in stone.

After I graduated, I went on a 3 month trip to just go around and take pictures of things. It was mostly hobbling around (not so) here and there. It's on my TODOs to upload some pictures of where I went. After those months of travel, I've been working full time doing some pretty neat AI + ML stuff. I've also been enjoying spending some of the new free time to learn better software practices. Currently focusing on Rust and Haskell (I promise it's to help with Rust.. but also a personal desire since I hear mathematicians like the language :).

Anyways, quick points on my research are below, will only write a little here but I'm happy to discuss further. Largely in LLMs (and some vision) consisting of:

- Studying the embedding spaces of deep neural networks (DNNs) and how we can extract interpretable, explainable, and high-level information about our data. Essentially it's about trying to unpack data that gets embedded by foundation models. In particular, I've been looking at different dimensionality reduction techniques to see what they tell us about the features of our data. A pretty big application is that we can use this to understand variance between human writing and AI-generated writing at a distributional level, but this applies to the image domain too (real images vs AI-generated images). There's also connections to understanding manifolds and other geometric objects associated to data such as raw text. You can find the preprint [by clicking here](https://www.arxiv.org/abs/2408.10437).

- Other stuff involving RAG-related tasks, in particular been looking at handling knowledge graph modalities. This has got a flavor of agentic AI and those other buzzwords we've been hearing about recently. Lots of playing with different models and the rest of the AI stack. Most recently there's been lots of playing around with using LLMs to create structured knowledge graphs and coming up with ways to evaluate techniques to this end.